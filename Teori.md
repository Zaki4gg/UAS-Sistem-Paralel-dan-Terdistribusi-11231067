## T1 (Bab 1) – Karakteristik sistem terdistribusi dan trade-off desain Pub-Sub aggregator

Sistem terdistribusi didefinisikan sebagai sekumpulan komputer otonom yang bagi pengguna tampak sebagai satu sistem terpadu. Karakteristik utamanya adalah resource sharing, concurrency, transparansi lokasi/kesalahan, latensi jaringan, dan kemungkinan partial failures dimana hanya sebagian node yang gagal (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Dalam desain Pub-Sub log aggregator, karakteristik ini tampak jelas: publisher, aggregator, dan storage berjalan pada container berbeda, berkomunikasi melalui HTTP dan database Postgres. Kelebihan pendekatan ini adalah skalabilitas (publisher bisa ditambah tanpa mengubah aggregator), isolasi kegagalan (jika publisher crash, database tetap konsisten), dan fleksibilitas deployment melalui Docker Compose. Trade-off-nya adalah meningkatnya kompleksitas koordinasi dan debugging karena harus menangani kegagalan antar service, eventual consistency antar komponen, serta kebutuhan observability yang lebih besar. Desain Pub-Sub juga mengorbankan strong coupling demi loose coupling berbasis event, sehingga end-to-end tracing menjadi lebih sulit. Dalam konteks tugas, trade-off tersebut dapat diterima karena tujuan utama adalah mendemonstrasikan mekanisme deduplikasi dan idempotent consumer di bawah beban tinggi, bukan sekadar throughput maksimal dari satu proses monolitik.

-------------------------------------------------------------------------------------------
## T2 (Bab 2) – Kapan memilih arsitektur publish–subscribe dibanding client–server?

Arsitektur client–server tradisional cocok ketika pola interaksi didominasi request–response sinkron, jumlah klien relatif terbatas, dan aplikasi menuntut strong consistency per operasi. Sebaliknya, model publish–subscribe dirancang untuk skenario di mana produsen tidak perlu mengetahui konsumen secara eksplisit, jumlah produsen dan konsumen dapat berubah dinamis, dan sistem dapat mentoleransi eventual consistency (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Pada log aggregator ini, pola kerja lebih mirip aliran event log: publisher hanya mengirim event ke endpoint /publish tanpa peduli kapan event diproses maupun siapa yang nantinya membaca hasil melalui /events atau /stats. Dengan Pub-Sub, sangat mudah menambah publisher baru ataupun consumer analitik tanpa mengubah layanan existing. Selain itu, arsitektur ini memudahkan implementasi idempotent consumer dan dedup di satu titik (aggregator/storage), sehingga tanggung jawab integritas data terpusat. Trade-off terhadap client–server murni adalah meningkatnya kompleksitas ketika menjamin ordering dan transaksi lintas komponen, namun hal ini diimbangi dengan penggunaan batching, upsert atomik, dan definisi eksplisit bahwa sistem mengimplementasikan at-least-once delivery alih-alih exactly-once.

-------------------------------------------------------------------------------------------
## T3 (Bab 3) – At-least-once vs exactly-once delivery; peran idempotent consumer

Model at-least-once delivery menjamin bahwa setiap pesan akan dikirimkan minimal satu kali, tetapi memungkinkan duplikasi. Sebaliknya, exactly-once delivery secara konseptual menginginkan setiap pesan diproses tepat satu kali, namun dalam praktik sulit dicapai di atas jaringan tak andal tanpa protokol transaksi terdistribusi yang rumit (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Dalam desain tugas, publisher dan skrip k6 sengaja mengirim duplikat (≥30%) untuk mensimulasikan at-least-once; tanggung jawab menghindari efek samping ganda dipindahkan ke consumer (aggregator) melalui pola idempotent consumer. Aggregator menyimpan setiap event pada tabel Postgres dengan unique constraint (topic, event_id) dan menjalankan INSERT ... ON CONFLICT DO NOTHING di dalam transaksi. Jika event yang sama tiba lagi, operasi insert menjadi no-op dan worker hanya meningkatkan counter duplicate_dropped. Dengan demikian, meskipun dari sisi jaringan pesan bisa terkirim berkali-kali, state akhir di database seolah-olah setiap event hanya diproses sekali. Pendekatan ini memberikan perilaku mendekati exactly-once di satu domain database, namun tetap realistis dan praktis untuk implementasi sistem terdistribusi.

-------------------------------------------------------------------------------------------
## T4 (Bab 4) – Skema penamaan topic dan event_id untuk dedup

Bab penamaan pada sistem terdistribusi menekankan pentingnya namespace yang jelas, jaminan keunikan, dan location independence dari identifier (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Dalam proyek ini, topic digunakan sebagai namespace fungsional (auth, orders, payment), sedangkan event_id berperan sebagai identifier unik di dalam masing-masing topik. Publisher membangkitkan event_id dengan pola seperti e-<number> yang unik per run; di sistem produksi pola tersebut bisa diganti UUID atau skema ID terdistribusi yang menggabungkan timestamp, ID node, dan counter monotonik. Kombinasi (topic, event_id) dijadikan kunci logis dan fisik di database melalui unique constraint. Dengan cara ini, generator event cukup menjamin keunikan lokal, sementara jaminan global “tidak ada event ganda diproses dua kali” ditegakkan oleh database. Pendekatan ini sejalan dengan anjuran literatur: sistem penamaan diekspos pada level aplikasi, tetapi enforcement konsistensi dilakukan oleh layanan infrastruktur seperti directory service atau sistem manajemen basis data yang mendukung constraint dan transaksi.

-------------------------------------------------------------------------------------------
## T5 (Bab 5) – Ordering praktis (timestamp + monotonic counter); batasan dan dampaknya

Literatur menjelaskan bahwa global total ordering di sistem terdistribusi mahal karena memerlukan koordinasi tambahan atau protokol seperti sequencer dan consensus. Banyak sistem praktis memilih partial ordering dengan memanfaatkan timestamp fisik dan counter lokal (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Di desain ini, setiap event membawa timestamp ISO8601 dari publisher dan dicatat ts_ingest di sisi aggregator, yaitu waktu ketika event disimpan. Untuk kebutuhan tugas, tidak disyaratkan total ordering lintas semua topik; yang penting adalah per topik tidak ada event yang hilang dan deduplikasi memastikan state akhir konsisten. Batasannya, bila dua publisher mengirim event hampir bersamaan, urutan yang terlihat di /events merefleksikan urutan commit di database, bukan selalu waktu kejadian asli. Hal ini dapat diterima untuk use case log dan analitik, tetapi tidak cocok untuk transaksi finansial yang menuntut serialisasi ketat. Dengan demikian, desain ini secara eksplisit memilih trade-off: tidak menggunakan layanan ordering khusus, namun tetap memberikan ordering praktis yang memadai bagi debugging, audit, dan metrik agregat.

-------------------------------------------------------------------------------------------
## T6 (Bab 6) – Failure modes dan mitigasi (retry, backoff, durable dedup store, crash recovery)

Bab toleransi kegagalan menyoroti berbagai mode kegagalan seperti crash, omission failure, dan timing failure, serta pentingnya strategi retry, replikasi, dan penyimpanan durabel (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Dalam proyek ini, beberapa failure mode diantisipasi: publisher dapat gagal di tengah pengiriman, aggregator dapat direstart, dan koneksi ke database dapat sementara terputus. Untuk mengatasinya, publisher dan k6 didesain stateless dan mampu melakukan retry dengan backoff; duplikasi akibat retry ditangani aman oleh idempotent consumer di aggregator. Dedup store disimpan di Postgres dengan volume pg_data, sehingga ketika container dihentikan atau di-recreate, event yang sudah diproses tetap tercatat dan tidak diproses ulang. Crash recovery aggregator diuji dengan menghentikan container aggregator lalu menyalakannya kembali dan memverifikasi bahwa nilai /stats dan isi /events tetap konsisten. Pendekatan ini mengikuti prinsip fail-fast and recover: aplikasi boleh sering di-restart, asalkan state kritis dipertahankan secara durabel dan semua operasi mutasi dibungkus dalam transaksi yang aman terhadap crash.

-------------------------------------------------------------------------------------------
## T7 (Bab 7) – Eventual consistency pada aggregator; peran idempotency + dedup

Konsep eventual consistency menyatakan bahwa replika atau komponen yang berbeda akan konvergen ke state yang sama bila tidak ada update baru untuk waktu tertentu, meskipun pada saat tertentu dapat menampilkan data tidak sinkron (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Dalam arsitektur Pub-Sub ini, alur publisher → aggregator → pembaca /events bersifat longgar terkopel. Saat load tinggi, mungkin ada jeda antara respons sukses /publish dan munculnya event di query /events atau konsistensi penuh di /stats. Akan tetapi, karena setiap event disimpan sebagai pasangan unik (topic, event_id) dan didukung idempotent upsert, state akhir database akan stabil setelah antrean pemrosesan kosong. Jika publisher melakukan retry agresif, duplicate_dropped akan naik, tetapi unique_processed tidak pernah melampaui jumlah event unik yang sebenarnya. Dengan demikian, sistem mengorbankan strong immediate consistency demi ketersediaan dan throughput, tetapi tetap menjamin bahwa setelah beberapa waktu tanpa beban baru, semua pembaca akan melihat log yang konsisten tanpa duplikasi.

-------------------------------------------------------------------------------------------
## T8 (Bab 8) – Desain transaksi: ACID, isolation level, dan strategi menghindari lost-update

Bab transaksi menekankan pentingnya properti ACID—atomicity, consistency, isolation, dan durability—untuk menjaga integritas data (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Pada tugas ini, setiap batch event yang masuk ke /publish diproses sebagai unit transaksi database. Insert ke tabel events dan pembaruan counter statistik received, unique_processed, dan duplicate_dropped dilakukan di dalam batas transaksi yang sama, sehingga bila terjadi error, seluruh batch dapat di-rollback. Konsistensi dijaga dengan constraint seperti NOT NULL dan unique key pada (topic, event_id). Isolation level Postgres minimal READ COMMITTED, yang cukup untuk mencegah dirty read dan mengurangi risiko lost-update ketika update counter memakai bentuk SET received = received + n. Durability disediakan oleh mekanisme WAL dan volume persisten pg_data. Pendekatan ini mencerminkan rekomendasi literatur bahwa logika kontrol konkurensi kritis sebaiknya didelegasikan ke sistem basis data transaksi, sehingga kode aplikasi menjadi lebih sederhana namun tetap aman terhadap anomali konkurensi.

-------------------------------------------------------------------------------------------
## T9 (Bab 9) – Kontrol konkurensi: locking/unique constraints/upsert; idempotent write pattern

Kontrol konkurensi dibutuhkan untuk mencegah konflik penulisan dan anomali seperti lost update, write skew, maupun dirty read ketika beberapa proses mengakses data yang sama secara bersamaan (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Implementasi proyek ini menghindari mekanisme explicit locking di level aplikasi, dan lebih banyak mengandalkan fitur PostgreSQL: row-level locking, MVCC, dan unique constraint. Worker yang memproses event mengeksekusi INSERT ... ON CONFLICT (topic, event_id) DO NOTHING, yang merupakan contoh idempotent write pattern: jika dua worker mencoba menulis event yang sama, hanya satu transaksi yang berhasil menambah baris baru, sementara yang lain menjadi no-op. Counter statistik diupdate dengan bentuk SET count = count + delta, yang aman pada isolation READ COMMITTED selama tidak ada logika baca-modifikasi-tulis manual. Pengujian konkurensi dengan beberapa worker dan stress test menunjukkan tidak adanya baris duplikat maupun double processing. Hal ini menunjukkan bahwa kombinasi constraint unik dan upsert atomik cukup untuk memenuhi tujuan Bab 9 tanpa memerlukan protokol locking yang rumit di kode aplikasi.

-------------------------------------------------------------------------------------------
## T10 (Bab 10–13) – Orkestrasi Compose, keamanan jaringan lokal, persistensi (volume), observability

Bab-bab akhir buku membahas layanan sistem seperti orkestrasi layanan web, keamanan, dan pemantauan (van Steen & Tanenbaum, 2023; Coulouris et al., 2011). Dalam proyek ini, Docker Compose berfungsi sebagai orkestrator yang mendefinisikan service aggregator, publisher, storage (Postgres), dan profil k6 untuk uji beban. Dependensi antar service diatur melalui depends_on dan health check, sehingga aggregator hanya mulai menerima beban ketika database dinyatakan sehat. Jaringan appnet dikonfigurasi sebagai bridge internal dengan internal: true, sehingga hanya port 8080 dari aggregator yang diekspos ke host; pendekatan ini mengikuti prinsip least exposure dan memperkuat keamanan jaringan lokal. Persistensi data dicapai dengan named volume pg_data yang dipasang ke direktori data Postgres, sehingga docker compose down tanpa -v tidak menghapus isi database. Dari sisi observability, sistem menyediakan endpoint /health dan /stats, log HTTP dari Uvicorn, dan log SQL dari Postgres yang digunakan untuk menganalisis performa dan perilaku di bawah beban. Kombinasi orkestrasi Compose, isolasi jaringan, volume persisten, dan metrik ini menunjukkan bagaimana konsep keamanan dan koordinasi sistem web diterapkan secara konkret.

-------------------------------------------------------------------------------------------
## Daftar Pustaka

Coulouris, G., Dollimore, J., Kindberg, T., & Blair, G. (2011). *Distributed systems: Concepts and design* (5th ed.). Pearson Education.

van Steen, M., & Tanenbaum, A. S. (2023). *Distributed systems* (4th ed.). Self-published.
